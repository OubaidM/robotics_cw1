{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a70bbd6",
   "metadata": {},
   "source": [
    "M00967179 + M009613339"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb572b",
   "metadata": {},
   "source": [
    "# Hot-Desk Detector - ROCm 6.0 + YOLOv11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32cdb4",
   "metadata": {},
   "source": [
    "#### **Hardware**:\n",
    "**GPU**: AMD Radeon RX6800XT (16GB VRAM) [Relevant for Batch and Imgsz]  \n",
    "**CPU**: AMD Ryzen 5 9600X (6Cores/12Threads) [Relevant for amount of Workers]  \n",
    "**RAM**: Crucial DDR5 Pro 32GB @6400MT/s [Relvant for cache:'ram']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537451d",
   "metadata": {},
   "source": [
    "**Model**: YOLOv11m  \n",
    "**Classes**: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158054d8",
   "metadata": {},
   "source": [
    "### Verify that the environment works and that the GPU is being detected  \n",
    "**Note**: If GPU is not detected, PyTorch will default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4845fb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî• PyTorch: 2.4.1+rocm6.0\n",
      "üéØ Ultralytics: 8.3.221\n",
      "üñ•Ô∏è  GPU: AMD Radeon RX 6800 XT\n",
      "‚úÖ ROCm available: True\n",
      "üìä CUDA devices: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "import numpy as np\n",
    "\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(f\"üéØ Ultralytics: {ultralytics.__version__}\")\n",
    "print(f\"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"‚úÖ ROCm available: {torch.cuda.is_available()}\")\n",
    "print(f\"üìä CUDA devices: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce0dc0",
   "metadata": {},
   "source": [
    "### Model Initialization  \n",
    "**Note**: The commented out bit is for the YOLOv8m model, which was used for initial testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe3bdf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ YOLO11m model loaded successfully!\n",
      "Model parameters: 20,114,688\n"
     ]
    }
   ],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load medium-sized YOLOv8 model\n",
    "# model = YOLO('yolov8m.pt')\n",
    "# print(\"‚úÖ YOLOv8m model loaded successfully!\")\n",
    "\n",
    "# # Display model architecture\n",
    "# print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL INITIALISATION ‚Äì YOLO11\n",
    "# ==========================================\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11m.pt\")          # Set to yolo11n.pt for way quicker experiments and if on CPU\n",
    "print(\"‚úÖ YOLO11m model loaded successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4050c2",
   "metadata": {},
   "source": [
    "### Phase 1  \n",
    "Full Dataset + Heavy Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0eb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase1 = dict(\n",
    "    data=\"data/data.yaml\",\n",
    "    epochs=200,\n",
    "    imgsz=640,                # Lower to 448 if having issues or on CPU.\n",
    "    batch=32,                 # Recommeded to lower to 8 if on CPU!!\n",
    "    workers=10,               # 10 out of 12 Threads is being used. DO NOT use all threads, it will cause your OS to crash.\n",
    "    device=0,                 # device=0 is GPU, change to device='cpu' for CPU.\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    lrf=0.05,\n",
    "    weight_decay=0.0005,\n",
    "    momentum=0.937,\n",
    "    warmup_epochs=3,\n",
    "    amp=True,                 # ROCm native AMP, set to False for CPU!!\n",
    "    half=False,               # keep FP32 BN \n",
    "    cache=\"ram\",              # 32 GB DDR5. Use cache=\"disk\" if the RAM cannot handle it.\n",
    "    compile=False,            # If True, training time will be faster, but caused issues on ROCm env so I set to False.       \n",
    "    patience=20,              # If mAP50 does not improve after 20 epochs, stop training.\n",
    "    project=\"hotdesk_training\",\n",
    "    name=\"yolo11m_phase1\",\n",
    "    exist_ok=True,\n",
    "    # ----- augmentation -----\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=5.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    copy_paste=0.1,\n",
    "    perspective=0.0005,\n",
    "    flipud=0.0,\n",
    "    # ----- loss -----\n",
    "    label_smoothing=0.05,\n",
    "    box=7.5,\n",
    "    cls=0.5,\n",
    "    dfl=1.5,\n",
    "    # ----- outputs -----\n",
    "    save_period=10,          # Saves model every 10 epoch so that progress is not loss on event of a system crash.\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "print(\"üî• STARTING PHASE-1 ‚Äì YOLO11m full-training\")\n",
    "results_p1 = model.train(**phase1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b918aa7",
   "metadata": {},
   "source": [
    "### Phase 2  \n",
    "Fine-tune best weight  \n",
    "i.e lower LR, lighter aug, longer epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffeb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT FORGET TO SET THE SAME TOGGLE AS ABOVE IF ON CPU!!\n",
    "from pathlib import Path\n",
    "model_path = Path('model/hotdest_final_model.pt') # Set this path to wherever the best.pt was generated from the above training.\n",
    "phase2 = dict(\n",
    "    data=\"data/data.yaml\",\n",
    "    epochs=50,                 # enough to drop LR 5√ó\n",
    "    imgsz=640,\n",
    "    batch=16,                  # smaller micro-batch ‚Üí stabler gradients\n",
    "    workers=8,                \n",
    "    device=0,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=1e-4,                  # 10√ó lower than phase-1\n",
    "    lrf=0.01,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=1,\n",
    "    amp=True,\n",
    "    half=False,\n",
    "    cache=\"ram\",\n",
    "    compile=False,             # keep off until ROCm fix\n",
    "    patience=20,\n",
    "    project=\"hotdesk_training\",\n",
    "    name=\"yolo11m_phase2_finetune\",\n",
    "    exist_ok=True,\n",
    "    # ----- LIGHTER AUG ‚Üí less distortion for mug/bottle -----\n",
    "    hsv_h=0.01,\n",
    "    degrees=2.0,\n",
    "    translate=0.05,\n",
    "    scale=0.2,\n",
    "    fliplr=0.5,\n",
    "    mosaic=0.5,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.0,\n",
    "    # ----- start from best -----\n",
    "    model=model_path, \n",
    ")\n",
    "\n",
    "print(\"üéØ STARTING PHASE-2 ‚Äì fine-tune best checkpoint\")\n",
    "model2 = YOLO(model_path)\n",
    "results_p2 = model2.train(**phase2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0869eb",
   "metadata": {},
   "source": [
    "### Phase 3  \n",
    "Micro fine-tune for underperformer: mug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424fa205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "from pathlib import Path\n",
    "model_path = Path('model/hotdest_final_model.pt') # Set this path to wherever the best.pt was generated from the above training.\n",
    "\n",
    "model3 = YOLO(model_path)\n",
    "\n",
    "# start training ‚Äì this creates model.trainer but does NOT run epochs yet\n",
    "model3.train(\n",
    "    data=\"data/data.yaml\",\n",
    "    epochs=10,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    workers=10,\n",
    "    device=0,\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=5e-5,\n",
    "    lrf=0.01,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=0,\n",
    "    amp=True,\n",
    "    cache=\"ram\",\n",
    "    compile=False,\n",
    "    patience=0,\n",
    "    project=\"hotdesk_training\",\n",
    "    name=\"yolo11m_mug_boost\",\n",
    "    exist_ok=True,\n",
    "    mosaic=0.2,\n",
    "    mixup=0.0,\n",
    "    copy_paste=0.8,\n",
    "    degrees=1.0,\n",
    "    translate=0.05,\n",
    "    scale=0.1\n",
    ")\n",
    "\n",
    "\n",
    "# ----- and start the actual epoch loop -----\n",
    "model3.trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25552a",
   "metadata": {},
   "source": [
    "### Model Evaluation  \n",
    "Run the model against the test-split (unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c38195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Comprehensive Test Set Evaluation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "model_path = Path('model/hotdest_final_model.pt') # Set this path to wherever the best.pt was generated from the above training.\n",
    "\n",
    "# Load model and test\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# Run evaluation with plots\n",
    "metrics = model.val(\n",
    "    data='data/data.yaml',\n",
    "    split='test',\n",
    "    device=0, # Change to device='cpu' if on CPU!!\n",
    "    plots=True,\n",
    "    verbose=True,\n",
    "    conf=0.15\n",
    ")\n",
    "\n",
    "print(\"üéØ FINAL TEST SET RESULTS:\")\n",
    "print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.4f}\") \n",
    "\n",
    "# Handle array precision/recall values\n",
    "precision = metrics.box.p\n",
    "recall = metrics.box.r\n",
    "\n",
    "# If they're arrays, take the mean\n",
    "if hasattr(precision, '__iter__'):\n",
    "    precision_mean = np.mean(precision)\n",
    "    recall_mean = np.mean(recall)\n",
    "else:\n",
    "    precision_mean = precision\n",
    "    recall_mean = recall\n",
    "\n",
    "print(f\"Precision: {precision_mean:.4f}\")\n",
    "print(f\"Recall: {recall_mean:.4f}\")\n",
    "\n",
    "# Calculate F1 Score (Micro-F1)\n",
    "f1_score = 2 * (precision_mean * recall_mean) / (precision_mean + recall_mean + 1e-16)\n",
    "print(f\"F1 Score (Micro): {f1_score:.4f}\")\n",
    "\n",
    "print(\"\\nüìä PER-CLASS TEST PERFORMANCE:\")\n",
    "class_names = ['mug', 'headset', 'mouse', 'stapler', 'notebook', 'pen', 'phone', 'bottle']\n",
    "class_f1_scores = []\n",
    "\n",
    "for i, class_idx in enumerate(metrics.box.ap_class_index):\n",
    "    class_name = class_names[int(class_idx)]\n",
    "    ap50 = metrics.box.ap50[i]\n",
    "    \n",
    "    # Get per-class precision and recall\n",
    "    if hasattr(metrics.box.p, '__iter__') and i < len(metrics.box.p):\n",
    "        class_precision = metrics.box.p[i]\n",
    "    else:\n",
    "        class_precision = precision_mean\n",
    "        \n",
    "    if hasattr(metrics.box.r, '__iter__') and i < len(metrics.box.r):\n",
    "        class_recall = metrics.box.r[i]\n",
    "    else:\n",
    "        class_recall = recall_mean\n",
    "    \n",
    "    # Calculate per-class F1\n",
    "    class_f1 = 2 * (class_precision * class_recall) / (class_precision + class_recall + 1e-16)\n",
    "    class_f1_scores.append(class_f1)\n",
    "    \n",
    "    print(f\"  {class_name}: AP50={ap50:.4f}, Precision={class_precision:.4f}, Recall={class_recall:.4f}, F1={class_f1:.4f}\")\n",
    "\n",
    "# Calculate Macro-F1 (average of per-class F1 scores)\n",
    "if class_f1_scores:\n",
    "    macro_f1 = np.mean(class_f1_scores)\n",
    "    print(f\"\\nüìà MACRO-F1 SCORE: {macro_f1:.4f}\")\n",
    "    \n",
    "    # Also show per-class F1 statistics\n",
    "    print(f\"   - Best F1: {np.max(class_f1_scores):.4f}\")\n",
    "    print(f\"   - Worst F1: {np.min(class_f1_scores):.4f}\")\n",
    "    print(f\"   - F1 Std: {np.std(class_f1_scores):.4f}\")\n",
    "else:\n",
    "    macro_f1 = 0.0\n",
    "    print(f\"\\nüìà MACRO-F1 SCORE: {macro_f1:.4f} (no per-class data available)\")\n",
    "\n",
    "print(f\"\\nüìä SUMMARY:\")\n",
    "print(f\"Micro-F1 (overall): {f1_score:.4f}\")\n",
    "print(f\"Macro-F1 (class-average): {macro_f1:.4f}\")\n",
    "\n",
    "print(f\"\\nüìà Plots saved to: {metrics.save_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
