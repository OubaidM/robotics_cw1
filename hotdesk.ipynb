{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a70bbd6",
   "metadata": {},
   "source": [
    "M00967179"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb572b",
   "metadata": {},
   "source": [
    "# Hot-Desk Detector - ROCm 6.0 + YOLOv11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d32cdb4",
   "metadata": {},
   "source": [
    "#### **Hardware**:\n",
    "**GPU**: AMD Radeon RX6800XT (16GB VRAM) [Relevant for Batch and Imgsz]  \n",
    "**CPU**: AMD Ryzen 5 9600X (6Cores/12Threads) [Relevant for amount of Workers]  \n",
    "**RAM**: Crucial DDR5 Pro 32GB @6400MT/s [Relvant for cache:'ram']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8537451d",
   "metadata": {},
   "source": [
    "**Model**: YOLOv11m  \n",
    "**Classes**: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158054d8",
   "metadata": {},
   "source": [
    "### Verify that the environment works and that the GPU is being detected  \n",
    "**Note**: If GPU is not detected, PyTorch will default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4845fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "import numpy as np\n",
    "\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(f\"üéØ Ultralytics: {ultralytics.__version__}\")\n",
    "print(f\"üñ•Ô∏è  GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"‚úÖ ROCm available: {torch.cuda.is_available()}\")\n",
    "print(f\"üìä CUDA devices: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ce0dc0",
   "metadata": {},
   "source": [
    "### Model Initialization  \n",
    "**Note**: The commented out bit is for the YOLOv8m model, which was used for initial testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bdf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ultralytics import YOLO\n",
    "\n",
    "# # Load medium-sized YOLOv8 model\n",
    "# model = YOLO('yolov8m.pt')\n",
    "# print(\"‚úÖ YOLOv8m model loaded successfully!\")\n",
    "\n",
    "# # Display model architecture\n",
    "# print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL INITIALISATION ‚Äì YOLO11\n",
    "# ==========================================\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolo11m.pt\")          # or yolo11s.pt for quicker experiments\n",
    "print(\"‚úÖ YOLO11m model loaded successfully!\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4050c2",
   "metadata": {},
   "source": [
    "### Phase 1  \n",
    "Full Dataset + Heavy Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0eb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K      1/200      15.3G      1.609      3.384       1.92        107        640: 15% ‚îÅ‚ï∏‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 23/151 1.1it/s 24.9s<1:59"
     ]
    }
   ],
   "source": [
    "phase1 = dict(\n",
    "    data=\"data.yaml\",\n",
    "    epochs=200,\n",
    "    imgsz=640,                # Lower to 448 if having issues or on CPU.\n",
    "    batch=32,                 # Recommeded to lower to 8 if on CPU!!\n",
    "    workers=10,               # 10 out of 12 Threads is being used. DO NOT use all threads, it will cause your OS to crash.\n",
    "    device=0,                 # device=0 is GPU, change to device='cpu' for CPU.\n",
    "    optimizer=\"AdamW\",\n",
    "    lr0=0.001,\n",
    "    lrf=0.05,\n",
    "    weight_decay=0.0005,\n",
    "    momentum=0.937,\n",
    "    warmup_epochs=3,\n",
    "    amp=True,                 # ROCm native AMP, set to False for CPU!!\n",
    "    half=False,               # keep FP32 BN\n",
    "    cache=\"ram\",              # 32 GB DDR5. Use cache=\"disk\" if the RAM cannot handle it.\n",
    "    compile=False,            # If True, training time will be faster, but caused issues on ROCm env so I set to False.       \n",
    "    patience=20,              # If mAP50 does not improve after 20 epochs, stop training.\n",
    "    project=\"hotdesk_training\",\n",
    "    name=\"yolo11m_phase1\",\n",
    "    exist_ok=True,\n",
    "    # ----- augmentation -----\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=5.0,\n",
    "    translate=0.1,\n",
    "    scale=0.5,\n",
    "    fliplr=0.5,\n",
    "    mosaic=1.0,\n",
    "    mixup=0.2,\n",
    "    copy_paste=0.1,\n",
    "    perspective=0.0005,\n",
    "    flipud=0.0,\n",
    "    # ----- loss -----\n",
    "    label_smoothing=0.05,\n",
    "    box=7.5,\n",
    "    cls=0.5,\n",
    "    dfl=1.5,\n",
    "    # ----- outputs -----\n",
    "    save_period=10,          # Saves model every 10 epoch so that progress is not loss on event of a system crash.\n",
    "    plots=True,\n",
    ")\n",
    "\n",
    "print(\"üî• STARTING PHASE-1 ‚Äì YOLO11m full-training\")\n",
    "results_p1 = model.train(**phase1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
